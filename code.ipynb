{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d02952e1-628f-4899-a17f-8819a18b6b70",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Clinical Intelligence System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e230462-24d0-4bbe-978a-191157c34f3a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Clinical intelligent system interprets clinical questions, retrieves relevant information from trusted medical sources, and generates factually accurate, context-aware responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32905df4-a9b1-4041-8329-0ef7e04a8676",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./.setup/learner_setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17bfe2d5-c6e2-4358-8473-93cead13900e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "import os\n",
    "import openai\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from dotenv import load_dotenv\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_openai import AzureOpenAIEmbeddings, AzureChatOpenAI\n",
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "from langchain.schema import Document\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "from deepeval.models.base_model import DeepEvalBaseLLM\n",
    "from deepeval.test_case import LLMTestCase, LLMTestCaseParams\n",
    "from deepeval import evaluate\n",
    "from deepeval.metrics import (\n",
    "    ContextualPrecisionMetric,\n",
    "    ContextualRecallMetric,\n",
    "    ContextualRelevancyMetric,\n",
    "    AnswerRelevancyMetric,\n",
    "    FaithfulnessMetric,\n",
    "    HallucinationMetric,\n",
    "    GEval,\n",
    ")\n",
    "\n",
    "from tenacity import (\n",
    "    retry,\n",
    "    stop_after_attempt,\n",
    "    wait_random_exponential,\n",
    ")\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1bc6f5d4-1db6-4466-90df-a9f3b970d89e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Authentication with the Azure API using client credentials.\n",
    "\n",
    "import httpx\n",
    "\n",
    "auth = \"https://api.uhg.com/oauth2/token\"\n",
    "client_id = dbutils.secrets.get(scope = \"AIML_Training\", key = \"client_id\")\n",
    "client_secret = dbutils.secrets.get(scope = \"AIML_Training\", key = \"client_secret\")\n",
    "scope = \"https://api.uhg.com/.default\"\n",
    "grant_type = \"client_credentials\"\n",
    "async with httpx.AsyncClient() as client:\n",
    "    body = {\n",
    "        \"grant_type\": grant_type,\n",
    "        \"scope\": scope,\n",
    "        \"client_id\": client_id,\n",
    "        \"client_secret\": client_secret,\n",
    "    }\n",
    "    headers = {\"Content-Type\": \"application/x-www-form-urlencoded\"}\n",
    "    resp = await client.post(auth, headers=headers, data=body, timeout=120)\n",
    "    token = resp.json()[\"access_token\"]\n",
    "\n",
    "load_dotenv(\"./Data/UAIS_vars.env\")\n",
    " \n",
    "AZURE_OPENAI_ENDPOINT = os.environ[\"MODEL_ENDPOINT\"]\n",
    "OPENAI_API_VERSION = os.environ[\"API_VERSION\"]\n",
    "CHAT_DEPLOYMENT_NAME = os.environ[\"MODEL_NAME\"]\n",
    "PROJECT_ID = os.environ[\"PROJECT_ID\"]\n",
    "EMBEDDINGS_DEPLOYMENT_NAME = os.environ[\"EMBEDDINGS_MODEL_NAME\"]\n",
    "\n",
    "chat_client = openai.AzureOpenAI(\n",
    "        azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "        api_version=OPENAI_API_VERSION,\n",
    "        azure_deployment=CHAT_DEPLOYMENT_NAME,\n",
    "        azure_ad_token=token,\n",
    "        default_headers={\n",
    "            \"projectId\": PROJECT_ID\n",
    "        }\n",
    "    )\n",
    "\n",
    "embeddings_client = openai.AzureOpenAI(\n",
    "    azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "    api_version=OPENAI_API_VERSION,\n",
    "    azure_deployment=EMBEDDINGS_DEPLOYMENT_NAME,\n",
    "    azure_ad_token=token,\n",
    "    default_headers={ \n",
    "        \"projectId\": PROJECT_ID\n",
    "    }\n",
    ") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f2a04440-7259-4c85-af51-9d3b2d222977",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Initialize AzureChatOpenAI model with the necessary parameters.\n",
    "\n",
    "chat_model = AzureChatOpenAI(\n",
    "    openai_api_version=OPENAI_API_VERSION,\n",
    "    azure_deployment=CHAT_DEPLOYMENT_NAME,\n",
    "    azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "    azure_ad_token=token,\n",
    "    default_headers={\"projectId\": PROJECT_ID},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d53d3007-ff71-403a-aa63-06a9bb431fe5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# This function sends a prompt to the chat model and retrieves the response.\n",
    "\n",
    "def get_response(prompt):\n",
    "    response = chat_client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            }\n",
    "        ],\n",
    "        model=CHAT_DEPLOYMENT_NAME\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb12d206-d9e1-46fc-9fe4-2a406fd015e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Wrap AzureChatOpenAI class wraps the AzureChatOpenAI model for use with DeepEval.\n",
    "\n",
    "class AzureChatModelWrapper(DeepEvalBaseLLM):\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def load_model(self):\n",
    "        return self.model\n",
    "\n",
    "    def generate(self, prompt: str) -> str:\n",
    "        return self.model.invoke(prompt).content\n",
    "\n",
    "    async def a_generate(self, prompt: str) -> str:\n",
    "        return (await self.model.ainvoke(prompt)).content\n",
    "\n",
    "    def get_model_name(self):\n",
    "        return \"gpt-4o-mini_2024-07-18\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0296fa0b-a2df-4587-9cc4-e3478d380cf1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Wrap initialized chat model for DeepEval\n",
    "\n",
    "wrapped_model = AzureChatModelWrapper(chat_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9486ee0a-b27e-4826-b07d-53db73af30d0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Dataset Loading and Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e794410-3157-47c2-8a9e-a5d70ae7dc11",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load and preprocess dataset\n",
    "data = pd.read_csv(\"./Data/capstone1_rag_dataset.csv\")\n",
    "documents = data['context'].tolist()\n",
    " \n",
    "# Wrap each document as LangChain Document\n",
    "docs = [Document(page_content=doc) for doc in documents]\n",
    "docs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "264ea426-d08d-4333-a468-c14763cddbe4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Embedding and Vector Store Creation\n",
    "\n",
    "In this section, we initialize the AzureOpenAIEmbeddings to generate embeddings for the documents. These embeddings are then stored in a local ChromaDB vector store. The process involves checking if a vector store already exists and loading it, or creating a new one if it doesn't.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2e26c22-f656-4d29-9b25-986e08b45a57",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# initialize the AzureOpenAIEmbeddings with the necessary parameters.\n",
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    azure_deployment=EMBEDDINGS_DEPLOYMENT_NAME,\n",
    "    api_version=OPENAI_API_VERSION,\n",
    "    azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "    azure_ad_token=token,\n",
    "    default_headers={\n",
    "        \"projectId\": PROJECT_ID\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "283f6c5e-d8e4-420c-87a6-7b815678a24d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# create and store embeddings in a local ChromaDB vector store.\n",
    "\n",
    "@retry(wait=wait_random_exponential(min=45, max=120), stop=stop_after_attempt(6))\n",
    "def store_embeddings(persist_directory,docs=None):\n",
    "    \"\"\"Create or use existing vector store for embeddings\"\"\"\n",
    "    \n",
    "    # Check if vector store already exists\n",
    "    if os.path.exists(persist_directory) and os.path.isdir(persist_directory):\n",
    "        print(f\"Loading existing vector store from {persist_directory}\")\n",
    "        # Load existing vector store\n",
    "        vector_store = Chroma(\n",
    "            persist_directory=persist_directory,\n",
    "            embedding_function=embeddings\n",
    "        )\n",
    "    else:\n",
    "        # Create new vector store\n",
    "        print(f\"Creating new vector store in {persist_directory}\")\n",
    "        vector_store = Chroma.from_documents(\n",
    "            docs,\n",
    "            embedding=embeddings,\n",
    "            persist_directory=persist_directory\n",
    "        )\n",
    "        vector_store.persist()\n",
    "    \n",
    "    return vector_store\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff323658-0380-48ab-97f7-5e57e761fd11",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# store the embeddings in directory.\n",
    "persist_directory = \"tmp/vector_embeddings_OPENAI\"\n",
    "vectorstore = store_embeddings(docs=docs, persist_directory=persist_directory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa53762a-6ce7-4b43-b41f-ba7c897f704d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Retrieval Strategy Exploration\n",
    "\n",
    "In this section, we explore different retrieval strategies to enhance document retrieval. We define a sample query and implement two retrieval methods: semantic search and hybrid search. \n",
    "\n",
    "Semantic search retrieves top-k semantically relevant documents using vector similarity, while hybrid search combines BM25 keyword matching with vector similarity for more diverse retrieval results. These strategies help in efficiently finding relevant documents for a given query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f7b04a58-aac6-4e1a-aa59-143f17b33492",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sample_query = \"Explain about Cohen syndrome\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ca9f5042-048b-4499-8f4a-578ddf98ef79",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# to retrieve top_k semantically relevant documents from ChromaDB using vector search.\n",
    "   \n",
    "def semantic_search(vectordb, query, top_k=3):\n",
    "    results = vectordb.similarity_search(query, k=top_k*2)  # fetch more to be safe\n",
    "    unique_results = []\n",
    "    seen_contents = set()\n",
    "\n",
    "    for doc in results:\n",
    "        if doc.page_content not in seen_contents:\n",
    "            unique_results.append(doc)\n",
    "            seen_contents.add(doc.page_content)\n",
    "        if len(unique_results) >= top_k:\n",
    "            break\n",
    "\n",
    "    return unique_results\n",
    "\n",
    "# Execute semantic search with the sample query    \n",
    "results_semantic_search = semantic_search(vectordb = vectorstore, query=sample_query, top_k =3)\n",
    "results_semantic_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b3e8b0d2-3288-46a5-b09c-1496cd508a4b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# to combine BM25 keyword matching with vector similarity for hybrid retrieval\n",
    "\n",
    "def hybrid_search(vectordb, query, top_k=3):\n",
    "    \"\"\"\n",
    "    Combines semantic and keyword search results for diverse retrieval.\n",
    "    \"\"\"\n",
    "    # Get semantic search results\n",
    "    semantic_results = vectordb.similarity_search(query, k=top_k*2)\n",
    "    semantic_contents = [doc.page_content for doc in semantic_results]\n",
    "    \n",
    "    # Get keyword search results\n",
    "    documents = [Document(page_content=doc) if isinstance(doc, str) else doc \n",
    "                for doc in vectordb.get()[\"documents\"]]\n",
    "    bm25_retriever = BM25Retriever.from_documents(documents)\n",
    "    keyword_results = bm25_retriever.get_relevant_documents(query, k=top_k*2)\n",
    "    \n",
    "    # Take half from semantic results\n",
    "    final_results = semantic_results[:top_k//2]\n",
    "    \n",
    "    # Add unique keyword results\n",
    "    for doc in keyword_results:\n",
    "        if len(final_results) >= top_k:\n",
    "            break\n",
    "        if doc.page_content not in semantic_contents:\n",
    "            final_results.append(doc)\n",
    "    \n",
    "    # Fill remaining spots with semantic results\n",
    "    remaining_spots = top_k - len(final_results)\n",
    "    if remaining_spots > 0:\n",
    "        start_idx = len(final_results) - remaining_spots\n",
    "        final_results.extend(semantic_results[start_idx:start_idx+remaining_spots])\n",
    "    \n",
    "    return final_results\n",
    "\n",
    "# Execute hybrid search with the sample query\n",
    "results_hybrid_search = hybrid_search(vectordb = vectorstore, query=sample_query, top_k =3)\n",
    "results_hybrid_search\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a6f49b33-84f4-4e37-8aab-1ca1474b45f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Generation Pipeline Integration\n",
    "In this section, we integrate various components to form a complete generation pipeline. This involves using the results from the retrieval strategies to rerank document chunks based on their relevance to a query. The top-ranked chunks are then used to generate a context-aware answer using a chat model. This integration ensures that the generated answers are both relevant and accurate, leveraging the strengths of both retrieval and generation techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "60c0c63c-6ba4-4592-949e-1cf1a6004bb8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# GPT rerank function uses GPT to rerank retrieved document chunks based on their relevance to the query.\n",
    "\n",
    "def rerank(query, retrieved_docs, top_k=3):\n",
    "    # Step 1: Prepare the ranking prompt\n",
    "    prompt = f\"\"\"You are an expert assistant helping to rank document chunks based on their relevance to the following question:\n",
    "\n",
    "    Question: {query}\n",
    "\n",
    "    Here are the chunks:\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    for i, doc in enumerate(retrieved_docs):\n",
    "        prompt += f\"Chunk {i+1}:\\n{doc.page_content.strip()}\\n\\n\"\n",
    "\n",
    "        prompt += f\"\"\"Instructions:\n",
    "    - Rank the chunks strictly based on their relevance to the question.\n",
    "    - You may return fewer than {top_k} chunks if fewer are relevant.\n",
    "    - If none of the chunks are relevant, return an empty list: []\n",
    "    - Respond only with the chunk numbers in descending order of relevance, like this:\n",
    "    Chunk 3, Chunk 1, Chunk 5\n",
    "    Or, if no relevant chunks are found, respond with:\n",
    "    []\n",
    "    \"\"\"\n",
    "\n",
    "    # Step 2: Call GPT for reranking\n",
    "    \n",
    "    gpt_output=get_response(prompt)\n",
    "    print(\"GPT Rerank Output:\\n\", gpt_output)\n",
    "\n",
    "    # Step 3: Extract chunk numbers from the output\n",
    "    chunk_order = [int(s.strip().split()[-1]) - 1 for s in gpt_output.split(',') if s.strip().startswith(\"Chunk\")]\n",
    "\n",
    "    # Step 4: Return sorted chunk objects\n",
    "    reranked_docs = [retrieved_docs[i] for i in chunk_order if i < len(retrieved_docs)]\n",
    "    return reranked_docs\n",
    "\n",
    "# Execute reranking with the hybrid search results\n",
    "results_reranked = rerank(query = sample_query, retrieved_docs = results_hybrid_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "69896185-9252-4e80-8878-51a1da483c75",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# to generate an answer using the top-ranked document chunks and the chat model.\n",
    "\n",
    "def generate_answer(query, top_chunks, model_name=CHAT_DEPLOYMENT_NAME):\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in top_chunks])\n",
    "    prompt = (\n",
    "        f\"You are an Expert Clinical AI assistant. Your task is to answer questions using **only** the information provided in the context below. Any information not found in the context must be excluded from your answer.\\n\\n\"\n",
    "        f\"Context:\\n{context}\\n\\n\"\n",
    "        f\"Question: {query}\\n\\n\"\n",
    "        f\"Instructions:\\n\"\n",
    "        f\"- First, identify the relevant facts from the context.\\n\"\n",
    "        f\"- Then, answer the question using only those facts.\\n\"\n",
    "        f\"- Do not use any external knowledge.\\n\"\n",
    "        f\"- Do not make assumptions or inferences beyond the context.\\n\"\n",
    "        f\"- If the answer is **not explicitly stated or directly inferable from the context**, respond exactly with: 'The question cannot be answered using the available documents.'\\n\"\n",
    "        f\"- If the question is out of scope or only partially answerable based on the context, clearly state the limitation and do not speculate.\\n\"\n",
    "        f\"- Before finalizing your answer, verify that every statement is directly supported by the context.\\n\\n\"\n",
    "        f\"Answer:\"\n",
    "    )\n",
    "\n",
    "    response = chat_client.chat.completions.create(\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0,\n",
    "        model=model_name\n",
    "    )\n",
    "    \n",
    "    gpt_output = response.choices[0].message.content\n",
    "    return gpt_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f6d5cd6a-f492-44d4-b9c6-70d5b1c99662",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# function to integrate semantic search, reranking, and answer generation into a single pipeline.\n",
    "def master_function(user_query, vectordb, semantic_search, rerank, generate_answer):\n",
    "    # Step 1: Perform semantic search to retrieve documents\n",
    "    retrieved_docs = semantic_search(query=user_query,vectordb=vectordb)\n",
    "    \n",
    "    # Extract page_content from LangChain Document objects\n",
    "    retrieved_docs_content = [doc.page_content for doc in retrieved_docs]\n",
    "    \n",
    "    # Step 2: Rerank the retrieved documents\n",
    "    top_chunks = rerank(query=user_query, retrieved_docs=retrieved_docs)\n",
    "    top_chunks_content = [doc.page_content for doc in top_chunks]\n",
    "\n",
    "    # Step 3: Generate an answer based on the top-ranked chunks\n",
    "    answer = generate_answer(query=user_query, top_chunks=top_chunks)\n",
    "    \n",
    "    # Return a dictionary with the question, retrieved documents, and generated answer\n",
    "    return {\n",
    "        \"question\": user_query,\n",
    "        \"retrieved_documents\": top_chunks_content,\n",
    "        \"generated_answer\": answer\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "078cc2f9-c647-4dfc-8b17-0645dbc6c49e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Validating RAG pipeline on evaluation dataset\n",
    "In this section, we validate the Retrieval-Augmented Generation (RAG) pipeline using an evaluation dataset. The process involves loading the dataset, extracting questions, and using the RAG pipeline to generate answers. The results are then compared against reference answers to assess the performance of the pipeline. This validation helps ensure that the system is generating accurate and contextually relevant responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d205842-331e-4c40-a79f-466799ae438f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# to load the validation dataset from a CSV file into a pandas DataFrame.\n",
    "val_data = pd.read_csv(\"./Data/capstone1_rag_validation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ce6f2b6-bd1b-4437-a8c4-29b148d4e7ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# to extract the questions, reference contexts, and reference answers from the validation dataset.\n",
    "questions_list = val_data['question'].tolist()\n",
    "reference_context_list = val_data['reference_context'].tolist()\n",
    "answers_list = val_data['reference_answer'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bf1b8512-68c1-4c86-acc6-4b46438abaae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Generate validation results\n",
    "val_results = []\n",
    "for question in questions_list:\n",
    "    row_data = master_function(\n",
    "        user_query=question, \n",
    "        vectordb = vectorstore,\n",
    "        semantic_search=semantic_search, \n",
    "        rerank=rerank, \n",
    "        generate_answer=generate_answer\n",
    "    )\n",
    "    val_results.append(row_data)\n",
    "val_data_results = pd.DataFrame(val_results)\n",
    "val_data_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "031912ab-87ca-4811-8f52-ce0f88d76842",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# precision metric function\n",
    "def precision_at_k(gpt_response,expected_answer,k=3):\n",
    "    k = k\n",
    "\n",
    "    test_case = LLMTestCase(\n",
    "        input=gpt_response['question'],\n",
    "        actual_output=gpt_response['generated_answer'],\n",
    "        expected_output=expected_answer,\n",
    "        retrieval_context=gpt_response['retrieved_documents'][:k]\n",
    "    )\n",
    "\n",
    "    metric = ContextualPrecisionMetric(\n",
    "        threshold=0.6,\n",
    "        model=wrapped_model,\n",
    "        include_reason=True,\n",
    "        verbose_mode=True\n",
    "    )\n",
    "\n",
    "    result = evaluate([test_case], [metric])\n",
    "    return result.test_results[0].metrics_data[0].score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b24cc0e-a2eb-41ac-97a3-e77d041ccc15",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# recall metric function\n",
    "def recall_at_k(gpt_response, expected_answer, k=3):\n",
    "    k = k\n",
    "    test_case = LLMTestCase(\n",
    "        input=gpt_response['question'],\n",
    "        actual_output=gpt_response['generated_answer'],\n",
    "        expected_output=expected_answer,\n",
    "        retrieval_context=gpt_response['retrieved_documents'][:k]\n",
    "    )\n",
    "\n",
    "    metric = ContextualRecallMetric(\n",
    "        threshold=0.6,\n",
    "        model=wrapped_model,\n",
    "        include_reason=True,\n",
    "        verbose_mode=True\n",
    "    )\n",
    "\n",
    "    result = evaluate([test_case], [metric])\n",
    "    return result.test_results[0].metrics_data[0].score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c90d2210-3f11-40d0-b93d-b8d55df22098",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# answer relevancy metric function\n",
    "def answer_relevancy_metric(gpt_response):\n",
    "    test_case = LLMTestCase(\n",
    "        input=gpt_response['question'],\n",
    "        actual_output=gpt_response['generated_answer'],\n",
    "    )\n",
    "\n",
    "    metric = AnswerRelevancyMetric(\n",
    "        threshold=0.6,\n",
    "        model=wrapped_model,\n",
    "        include_reason=True,\n",
    "        verbose_mode=True\n",
    "    )\n",
    "\n",
    "    result = evaluate([test_case], [metric])\n",
    "    return result.test_results[0].metrics_data[0].score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5107ece8-29df-443e-a492-29ac78a2db17",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# faithfulness metric function\n",
    "def faithfulness_metric(gpt_response):\n",
    "    test_case = LLMTestCase(\n",
    "        input=gpt_response['question'],\n",
    "        actual_output=gpt_response[\"generated_answer\"],\n",
    "        retrieval_context=gpt_response['retrieved_documents']\n",
    "    )\n",
    "\n",
    "    metric = FaithfulnessMetric(\n",
    "        threshold=0.6,\n",
    "        model=wrapped_model,\n",
    "        include_reason=True,\n",
    "        verbose_mode=True\n",
    "    )\n",
    "\n",
    "    result = evaluate([test_case], [metric])\n",
    "    return result.test_results[0].metrics_data[0].score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b00dfd2f-a1a1-409d-8e4a-3b748fa0a024",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Hallucination metric function\n",
    "def hallucination_metric(gpt_response, expected_answer):\n",
    "    test_case = LLMTestCase(\n",
    "        input=gpt_response['question'],\n",
    "        actual_output=gpt_response['generated_answer'],\n",
    "        context=[expected_answer]\n",
    "    )\n",
    "\n",
    "    metric = HallucinationMetric(\n",
    "        threshold=0.6,\n",
    "        model=wrapped_model,\n",
    "        include_reason=True,\n",
    "        verbose_mode=False\n",
    "    )\n",
    "\n",
    "    result = evaluate([test_case], [metric])\n",
    "    return result.test_results[0].metrics_data[0].score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "37b3fdf0-2f4a-479e-adf1-c7d03b74288d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Evaluating metrics\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "answer_relevancy_scores = []\n",
    "faithfulness_scores = []\n",
    "hallucination_scores = []\n",
    "\n",
    "results_val = val_data_results\n",
    "\n",
    "for index, row in results_val.iterrows():\n",
    "    expected_answer = answers_list[index]\n",
    "    expected_context = reference_context_list[index]\n",
    "    gpt_response = row\n",
    "\n",
    "    # Retriver Evaluation Metrics\n",
    "    precision = precision_at_k(gpt_response, expected_context, k=3)    \n",
    "    recall = recall_at_k(gpt_response, expected_context, k=3)\n",
    "\n",
    "    # Generator Evaluation Metrics:\n",
    "    answer_relevancy = answer_relevancy_metric(gpt_response)\n",
    "    faithfulness = faithfulness_metric(gpt_response)\n",
    "    hallucination = hallucination_metric(gpt_response, expected_answer)\n",
    "\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    answer_relevancy_scores.append(answer_relevancy)\n",
    "    faithfulness_scores.append(faithfulness)\n",
    "    hallucination_scores.append(hallucination)\n",
    "\n",
    "results_val['precision@K'] = precision_scores\n",
    "results_val['recall@K'] = recall_scores\n",
    "results_val['answer_relevancy_score'] = answer_relevancy_scores\n",
    "results_val['faithfulness_score'] = faithfulness_scores\n",
    "results_val['hallucination_score'] = hallucination_scores\n",
    "results_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "859d2feb-d128-4a79-b415-be08ab18bcdb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Predictions on test dataset\n",
    "In this section, we focus on generating predictions for the test dataset. The process involves loading the test questions from a CSV file, applying the RAG pipeline to generate answers, and storing the results. This step is crucial for evaluating the model's performance on unseen data and preparing the results for submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c8a514f-9f06-4669-96d4-cf1fb4b4ef1b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# loads the test dataset from a CSV file into a pandas DataFrame.\n",
    "test_data = pd.read_csv(\"./Data/capstone1_rag_test_questions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d19f457-b56a-430e-9dd8-bc70e41c20fe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "test_questions_list = test_data['question'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "48c68644-e78e-4a05-9001-edd5b6709057",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Generate test results\n",
    "test_results = []\n",
    "for question in test_questions_list:\n",
    "    row_data = master_function(\n",
    "        user_query=question, \n",
    "        vectordb = vectorstore,\n",
    "        semantic_search=semantic_search, \n",
    "        rerank=rerank, \n",
    "        generate_answer=generate_answer\n",
    "    )\n",
    "    test_results.append(row_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "31ef63ac-ca00-4c90-9f30-7f78bdf54494",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Convert test results to a DataFrame\n",
    "final_test_df = pd.DataFrame(test_results)\n",
    "# Export DataFrame to CSV\n",
    "final_test_df.to_csv('submission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "code",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}